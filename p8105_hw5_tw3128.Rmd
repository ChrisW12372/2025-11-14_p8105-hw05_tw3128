---
title: "p8105_hw5_tw3128"
author: "Chris"
date: "2025-11-14"
output: github_document
---

```{r include = FALSE}
library(tidyverse)
library(broom)
library(purrr)

set.seed(20251114)
```


# Problem One


## fixed group size

```{r}
one_birthday_trial = function(n){
  birthdays = sample(1:365, size = n, replace = TRUE)
  repeated_bday <- length(unique(birthdays)) < n
  repeated_bday
}

one_birthday_trial(300)
```


## monte carlo simulation

```{r}
estimate_bdays_prob <- function(n, B = 10000) {
  if(!is.numeric(n)){
    stop("n must be numeric.")
  }
  mean(
    replicate(B, one_birthday_trial(n))
    )
}
```


```{r}
df_prob <- 
  expand_grid(n = 2:50) |>
  rowwise() |>
  mutate(prob = estimate_bdays_prob(n)) |>
  ungroup()

df_prob
```


## plotting

```{r}
df_prob |>
  ggplot(aes(x = n, y = prob)) +
  geom_line(alpha = 0.8, color = "#5a6acd") +
  labs(
    title = "Estimated Probability of Birthday Problem (2-50)",
    x = "n (group size)",
    y = "Probability"
  )
```

* Overall Trend    
  * The probability of two people sharing the same birthday increased monotonically as n increases from 2 to 50.  
  * Larger groups generate more possible pairs, which naturally raises the chance of a shared birthday.  
    
* Birthday Paradox    
  * When `n = 23`, the probability is already larger than `0.5`, which feels counterintuitive because 23 is far smaller than 365.  
  * The reason is that the number of pairs is $\frac{n \times (n - 1)}{2}$, which can be larger than 365 even when n is small.  
  


# Problem Two


## one sample t-test for $\mu = 0$

```{r}
simulate_tt = function(mu, n = 30, sigma = 5, B = 5000){
  replicate(
    B, {
      x <- rnorm(n = n, mean = mu, sd = sigma)
      tt <- t.test(x, mu = 0, )
      df_tt_tidy <- tidy(tt)
      df_estimations <- 
        tibble(mu_hat = df_tt_tidy$estimate, p_value = df_tt_tidy$p.value)
    },
    simplify = FALSE) |>
    
    bind_rows() |>
    mutate(id = row_number()) |>
    relocate(id)
}

sim0 <- simulate_tt(0)
```


## when $\mu$ equals other values

```{r}
mu_values <- 1:6

df_power <-
  map_dfr(
    mu_values,
    function(true_mu){
      sim <- simulate_tt(true_mu)
      power <- mean(sim$p_value < 0.05)
      
      tibble(
        true_mu ,
        power 
      )
    }
  )

df_power |>
  ggplot(aes(x = true_mu, y = power)) + 
  geom_line(color = "#6a5acd") + geom_point(size = 2, color = "steelblue") +
  labs(
    title = "The Relationship Between Power and Effect Size",
    x = expression("real " *  mu),
    y = "power"
  )
```


* Overall Trend  
  * The powers of simple t tests increase monotonically when $\mu$ increases from 1 to 6.  
  
* Segmented Conditions  
  * When `$\mu$ = 1`, even though the null hypothesis is wrong, the power of testing is still low.  
  * With the true mean increases, the power of testing increases sharply.  


## are the estimations unbiased or not

```{r}
mu_values <- 0:6

df_mu_hat <- 

  map_dfr(
    mu_values,
    function(true_mu){
      sim <- simulate_tt(true_mu)
      avg_mu_hat <- mean(sim$mu_hat)
      avg_reject <- mean(sim$mu_hat[sim$p_value < 0.05], na.rm = TRUE)
      
      tibble(
        true_mu ,
        avg_mu_hat,
        avg_reject
      )
    }
  )

df_mu_hat |>
  ggplot(aes(x = true_mu, y = avg_mu_hat)) +
  geom_line(color = "#5a6") + geom_point(size = 2, color = "red")

df_mu_hat |>
  ggplot(aes(x = true_mu, y = avg_reject)) +
  geom_abline(intercept = 0, slope = 1, color = "pink") +
  geom_line(color = "#5a6") + geom_point(size = 2, color = "red") +
  labs(
    title = expression("Averege " * hat(mu) * " vs Real Expectations When Significant")
  )
```

* No, the average $\mu_(hat)$ is not equal to the real expectation when significant. Instead, it is systematically larger than the true mean.  
* This happens because we are conditioning on statistical significance (p < 0.05).
When μ is small, only samples with unusually large positive estimation errors are likely to produce a significant result and lead to rejection of the null. As a result, the subset of significant samples is biased.  



# Problem Three

```{r}
df_homicide <- read_csv("data/homicide-data.csv")
```


## create "city_state" and describe the dataset

```{r}
df_homicide <-
  df_homicide |>
  mutate(city_state = paste(city, state, sep = ", "))

df_city_summary <-
  df_homicide |>
  group_by(city_state) |>
  summarise(
    total_homicide = n(),
    unsolved_homicide = sum(disposition %in% c("Closed without arrest", "Open/No arrest"))
  )

df_city_summary
```


The homicide dataset consists of individual-level case records compiled by the Washington Post. Each row represents a single homicide. The dataset includes:  
  * Demographic Data: name, age, sex, and race  
  * Location: city, state, latitude and longitude  
  * Time: reported_date  
  * Case disposition: whether the case was “Closed by arrest”, “Closed without arrest”, or remains “Open/No arrest”  
In total, the dataset contains `r nrow(df_homicide)` observations and `r ncol(df_homicide) - 1` variables.  


## Baltimore

```{r}
df_btm <-
  df_city_summary |>
  filter(city_state == "Baltimore, MD") 

btm_total <- df_btm$total_homicide
btm_unsolved <- df_btm$unsolved_homicide

df_tt_btm <- prop.test(btm_unsolved, btm_total) |>
  broom::tidy() |>
  select(estimate, conf.low, conf.high) |>
  janitor::clean_names()
```


## all cities

```{r}
df_tt_all <-
  df_city_summary |>
  mutate(
    test = map2(unsolved_homicide, total_homicide, ~ prop.test(.x, .y)),
    tidy_test = map(test, ~ tidy(.x))
  ) |>
  unnest(tidy_test) |>
  select(city_state, estimate, conf.low, conf.high) |>
  janitor::clean_names()
```

## plotting

```{r}
df_plot <-
  df_tt_all |>
  arrange(estimate) |>
  mutate(city_state = factor(city_state, levels = city_state))

ggplot(df_plot, aes(x = city_state, y = estimate)) +
  geom_point(color = "red") +
  geom_errorbar(aes(ymin = conf_low, ymax = conf_high), width = 0.2) +
  labs(
    title = "Estimated Proportion of Unsolved Homicides by City",
    x = "City",
    y = "Estimated Unsolved Proportion"
  ) +
   theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)
  )

```

















































